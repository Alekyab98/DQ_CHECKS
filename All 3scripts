import csv
import subprocess
import json
from datetime import datetime, timezone
from urllib.parse import quote
import os
import pandas as pd

def load_api_keys(filename):
    api_keys = {}
    with open(filename, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                function_name, key = line.split(':', 1)
                api_keys[function_name] = key.strip()
    return api_keys

def convert_epoch_to_timestamp(value):
    return datetime.fromtimestamp(int(value), tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')

def execute_curl_and_get_data(curl_command):
    bash_command = f'bash -c "{curl_command}"'
    result = subprocess.run(bash_command, shell=True, capture_output=True, text=True)

    if not result.stdout:
        print(f"Empty response from curl command.")
        return None
    
    if result.returncode != 0:
        print(f"Error executing curl command: {result.stderr}")
        return None

    return result.stdout

def create_txt_files_from_csv(input_csv, output_txt):
    with open(input_csv, 'r') as csv_file, open(output_txt, 'w') as txt_file:
        reader = csv.DictReader(csv_file)
        for row in reader:
            txt_file.write(f"{row['metric_name']} | {row['query']}\n")
    print(f"TXT file created: {output_txt}")

def create_csv_for_kpi(kpi_name, query, function_name, encoded_api_key, priority_type, output_folder):
    encoded_query = quote(query)
    start_epoch = '1731369600'
    end_epoch = '1731452400'
    curl_command = (
        f"curl --location --globoff 'https://us.aether.nss.vzwnet.com/gem/prometheus/api/v1/query_range?"
        f"query={encoded_query}&start={start_epoch}&end={end_epoch}&step=60m'"
        f" --header 'Authorization: Basic {encoded_api_key}'"
    )

    response_data = execute_curl_and_get_data(curl_command)
    if response_data is None:
        print(f"Skipping CSV creation for {kpi_name} due to empty or invalid response.")
        return

    try:
        json_data = json.loads(response_data)
    except json.JSONDecodeError as e:
        print(f"Failed to parse JSON for {kpi_name}. Error: {e}")
        print(f"Raw response was: {response_data}")
        return

    value_list = []

    if json_data.get('status') == 'success' and 'data' in json_data and 'result' in json_data['data']:
        for result in json_data['data']['result']:
            fqdn = result['metric'].get('localdn', 'unknown') if function_name == 'upf' else result['metric'].get('kubernetes_namespace', 'unknown')
            for v in result['values']:
                event_time = convert_epoch_to_timestamp(v[0])
                metric_value = v[1]
                value_list.append({
                    "fqdn": fqdn,
                    "metric_value": metric_value,
                    "event_time": event_time,
                    "metric_name": kpi_name,
                    "function_name": function_name,
                    "priority_type": priority_type
                })
    else:
        print(f"Invalid data in the response for {kpi_name}.")
        return
    
    safe_kpi_name = quote(kpi_name, safe='')

    csv_filename = f'{output_folder}/{function_name}_{safe_kpi_name}.csv'

    with open(csv_filename, mode='w', newline='') as file:
        writer = csv.DictWriter(file, fieldnames=["function_name", "event_time", "fqdn", "metric_name", "metric_value", "priority_type"])
        writer.writeheader()
        writer.writerows(value_list)

    print(f'CSV file created for {kpi_name}: {csv_filename}')

def load_shortlisted_metrics(filename):
    shortlisted_metrics = set()
    with open(filename, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                shortlisted_metrics.add(line)
    return shortlisted_metrics

def concatenate_csv_files(output_folder, final_csv):
    all_files = [os.path.join(output_folder, f) for f in os.listdir(output_folder) if f.endswith('.csv')]
    combined_df = pd.concat(pd.read_csv(f) for f in all_files)
    combined_df.to_csv(final_csv, index=False)
    print(f"Final concatenated CSV file created: {final_csv}")

# Step 1: Create TXT files from CSV
create_txt_files_from_csv('amf.csv', 'amf_offset.txt')
create_txt_files_from_csv('smf.csv', 'smf_fqdn.txt')
create_txt_files_from_csv('upf.csv', 'upf_offset.txt')

# Step 2: Use TXT files to create CSV files
api_keys = load_api_keys('api_keys.txt')
shortlisted_metrics = load_shortlisted_metrics('shortlisted_kpis.csv')
input_files = {
    'amf_offset.txt': 'amf',
    'smf_fqdn.txt': 'smf',
    'upf_offset.txt': 'upf'
}

output_folder = r"C:\Users\billaal\Documents\python\All_metrics\CSV files\CSV_amf_smf_upf_12nov"

for input_file, function_name in input_files.items():
    encoded_api_key = api_keys.get(function_name)
    if not encoded_api_key:
        print(f"Skipping {input_file} due to missing API key for {function_name}.")
        continue

    with open(input_file, 'r') as file:
        for line in file:
            line = line.strip()
            if '|' in line:
                try:
                    metric_name, query = [part.strip() for part in line.split('|', 1)]
                    priority_type = 'P1' if metric_name in shortlisted_metrics else 'P2'
                    create_csv_for_kpi(metric_name, query, function_name, encoded_api_key, priority_type, output_folder)
                except ValueError:
                    print(f"Error unpacking line: {line}")
            else:
                print(f"Skipping line due to incorrect format: {line}")

# Step 3: Concatenate CSV files
final_csv = r"C:\Users\billaal\Documents\python\All_metrics\final_combined_metrics.csv"
concatenate_csv_files(output_folder, final_csv)

print("All steps completed successfully.")
